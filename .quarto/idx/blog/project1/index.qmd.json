{"title":"A Replication of Karlan and List (2007)","markdown":{"yaml":{"title":"A Replication of Karlan and List (2007)","author":"Dingran Wang","date":"04/21/2025","callout-appearance":"minimal"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nTo explore how different fundraising strategies influence donor behavior, Karlan and List leveraged a natural field experiment in collaboration with a real nonprofit organization. The 50,000 prior donors were randomly assigned to receive one of several versions of a direct mail solicitation. The control group received a standard appeal, while treatment groups received letters offering matching grants at different match ratios—1:1, 2:1, or 3:1. Each variation also manipulated the suggested donation amount and the maximum size of the matching gift. By analyzing the response rate and donation amounts across treatments, the authors were able to isolate the causal impact of these fundraising tactics on charitable giving.\n\nThis project seeks to replicate their results.\n\n\n## Data\n\n### Description\n\n```{python}\n#| echo: false\nimport pandas as pd\n\ndf = pd.read_stata(\"/Users/danielwang/Desktop/UCSD Spring/MGTA495 Marketing Analytics/Website/blog/project1/data/karlan_list_2007.dta\")\n\n```\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n```{python}\nimport statsmodels.api as sm\nfrom scipy import stats\n\n# Load data\ndf['treat'] = df['treatment'].fillna(0)\n\n# Balance test function\ndef balance_test(var):\n    df_sub = df[['treat', var]].dropna()\n    treat_group = df_sub[df_sub['treat'] == 1][var]\n    control_group = df_sub[df_sub['treat'] == 0][var]\n    \n    # T-test\n    t_stat, p_val = stats.ttest_ind(treat_group, control_group, equal_var=True)\n    mean_diff = treat_group.mean() - control_group.mean()\n\n    print(f\"\\n==== Balance Test for '{var}' ====\")\n    print(f\"T-test:\")\n    print(f\"  Mean (Treatment): {treat_group.mean():.3f}\")\n    print(f\"  Mean (Control):   {control_group.mean():.3f}\")\n    print(f\"  Difference:       {mean_diff:.3f}\")\n    print(f\"  t-statistic:      {t_stat:.3f}\")\n    print(f\"  p-value:          {p_val:.4f}\")\n\n    # OLS\n    X = sm.add_constant(df_sub['treat'])\n    model = sm.OLS(df_sub[var], X).fit()\n    print(\"\\nOLS Regression:\")\n    print(model.summary().tables[1])\n\n# Run tests\nfor var in ['mrm2', 'freq', 'hpa']:\n    balance_test(var)\n```\n\n## Experimental Results\nIn all cases, the null hypothesis of equal means cannot be rejected, and both t-tests and OLS regressions yield identical conclusions. The treatment assignment is statistically uncorrelated with these pre-treatment variables, providing strong evidence that the randomization mechanism worked as intended.\n\nWhy this matters: Table 1 in Karlan & List (2007) serves the same purpose—showing that groups were well-balanced at baseline. This is essential for internal validity: it ensures that any post-treatment differences in giving behavior can be credibly attributed to the treatment itself, not to pre-existing differences between donors.\n\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\n```{python}\n#| echo: false\nimport matplotlib.pyplot as plt\n\n# Create treatment indicator\ndf['treat'] = df['treatment'].fillna(0)\n\n# Group by treatment and compute mean of 'gave' (binary)\nprop_donated = df.groupby('treat')['gave'].mean()\n\n# Plot\nplt.bar(['Control', 'Treatment'], prop_donated, edgecolor='black')\nplt.title(\"Proportion of Donors by Treatment Group\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.ylim(0, 0.03)\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.show()\n```\n\nThe barplot below shows that 2.20% of individuals in the treatment group donated, compared to 1.79% in the control group.\n\n\n```{python}\n# T-test\ngave_treat = df[df['treat'] == 1]['gave']\ngave_control = df[df['treat'] == 0]['gave']\nt_stat, p_val = stats.ttest_ind(gave_treat, gave_control, equal_var=True)\n\nprint(\"T-test results:\")\nprint(f\"  Mean (Treatment): {gave_treat.mean():.4f}\")\nprint(f\"  Mean (Control):   {gave_control.mean():.4f}\")\nprint(f\"  Difference:       {gave_treat.mean() - gave_control.mean():.4f}\")\nprint(f\"  t-statistic:      {t_stat:.3f}\")\nprint(f\"  p-value:          {p_val:.4f}\")\n\n# OLS regression\nX = sm.add_constant(df['treat'])\nols_model = sm.OLS(df['gave'], X).fit()\nprint(\"\\nOLS Regression:\")\nprint(ols_model.summary().tables[1])\n```\n\nThe t-test and regression agree: the difference is statistically significant at the 1% level. Offering a matching grant increased the response rate by about 0.42 percentage points, which is approximately a 22% increase relative to the control group's donation rate.\n\n\n```{python}\n# Probit model\nprobit_model = sm.Probit(df['gave'], X).fit()\nprint(probit_model.summary())\n```\n\nThis replicates Table 3, Column 1 in the original paper, confirming that the treatment has a positive and statistically significant effect on the probability of donating.\n\nThese results show that simply informing potential donors that their gift would be matched made them more likely to give. Even though the absolute increase in donation rate is small, the relative effect is large and meaningful for fundraisers.\n\nThis supports the idea that donors are motivated not only by altruism, but also by how effective or impactful their contribution feels. The matching grant may act as a psychological signal that \"now is a good time to give\" or that their donation is more valuable than usual.\n\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n```{python}\n# treatment\ntreat_df = df[df['treat'] == 1].copy()\n\n# 1:1 vs 2:1\ngave_1 = treat_df[treat_df['ratio'] == 1]['gave']\ngave_2 = treat_df[treat_df['ratio'] == 2]['gave']\nt12, p12 = stats.ttest_ind(gave_1, gave_2)\n\n# 2:1 vs 3:1\ngave_3 = treat_df[treat_df['ratio'] == 3]['gave']\nt23, p23 = stats.ttest_ind(gave_2, gave_3)\n\nprint(f\"1:1 vs 2:1 match rate — p = {p12:.4f}\")\nprint(f\"2:1 vs 3:1 match rate — p = {p23:.4f}\")\nprint(f\"Means: 1:1 = {gave_1.mean():.4f}, 2:1 = {gave_2.mean():.4f}, 3:1 = {gave_3.mean():.4f}\")\n\n```\n\nThe results show no statistically significant differences in donation rates between the match levels. While there is a slight increase in the mean from 1:1 to 2:1 and 3:1, the p-values (0.33 and 0.96) confirm that these differences are not distinguishable from zero at conventional significance levels.\n\n\n```{python}\n# dummy\ntreat_df['ratio1'] = (treat_df['ratio'] == 1).astype(int)\ntreat_df['ratio2'] = (treat_df['ratio'] == 2).astype(int)\ntreat_df['ratio3'] = (treat_df['ratio'] == 3).astype(int)\n\n# ratio1\nX = sm.add_constant(treat_df[['ratio2', 'ratio3']])\ny = treat_df['gave']\nratio_model = sm.OLS(y, X).fit()\nprint(ratio_model.summary().tables[1])\n\n```\n\nThis regression supports the t-test findings. Neither the 2:1 nor 3:1 match ratio has a statistically significant effect relative to the 1:1 match. This aligns closely with Karlan & List’s statement that “larger match ratios… had no additional impact” (p. 8).\n\n\n```{python}\ndiff_21 = gave_2.mean() - gave_1.mean()\ndiff_32 = gave_3.mean() - gave_2.mean()\n\n# OLS \ncoef_diff_21 = ratio_model.params['ratio2']\ncoef_diff_32 = ratio_model.params['ratio3'] - ratio_model.params['ratio2']\n\nprint(f\"Data-based diff (2:1 - 1:1): {diff_21:.4f}\")\nprint(f\"Data-based diff (3:1 - 2:1): {diff_32:.4f}\")\nprint(f\"Model-based diff (2:1 - 1:1): {coef_diff_21:.4f}\")\nprint(f\"Model-based diff (3:1 - 2:1): {coef_diff_32:.4f}\")\n\n```\n\nBoth direct comparisons and model-based coefficient differences tell the same story: moving from 1:1 to 2:1 yields a small and statistically insignificant increase, and going from 2:1 to 3:1 yields essentially no change at all.\n\nThese results suggest that offering a match increases the chance of donation, but increasing the match ratio further does not enhance this effect. In other words, once the donor sees their gift will be matched, the degree of matching is not very motivating. This supports the notion that framing and salience—not just raw incentive size—drive much of charitable behavior.\n\nThis provides valuable insights for fundraisers: even modest matching offers (1:1) may be just as effective as more expensive ones (2:1 or 3:1) in driving participation.\n\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nT-test / Regression on Full Sample\n```{python}\n# reg\nX_full = sm.add_constant(df['treat'])\ny_amount = df['amount']\nmodel_full = sm.OLS(y_amount, X_full).fit()\n\nprint(\"OLS on all individuals:\")\nprint(model_full.summary().tables[1])\n```\nDependent variable: donation amount (all individuals)\n\n\nThis suggests that offering a matching grant increased the average donation amount by about $0.15. However, the result is only marginally significant (p ≈ 0.063). Since this regression includes non-donors (who gave $0), the result likely reflects the fact that more people gave at all in the treatment group.\n\n\nRegression Conditional on Donation\n```{python}\n# limit\ndf_positive = df[df['gave'] == 1]\n\nX_cond = sm.add_constant(df_positive['treat'])\ny_cond_amount = df_positive['amount']\nmodel_cond = sm.OLS(y_cond_amount, X_cond).fit()\n\nprint(\"\\nOLS on donors only (conditional on giving):\")\nprint(model_cond.summary().tables[1])\n```\n\nAmong those who actually donated, individuals in the treatment group gave slightly less, on average, than those in the control group—but this difference is small and statistically insignificant.\n\nThis suggests that the treatment did not affect how much people gave, once they decided to give. The treatment influenced the extensive margin (whether to donate), but not the intensive margin (how much to donate).\n\nCausal note: Since we are conditioning on a post-treatment outcome (gave), the regression on donors only does not have a causal interpretation. It is, however, still descriptively valuable.\n\n\n\nHistograms of Donation Amounts (Among Donors)\n```{python}\n#| echo: false\nimport matplotlib.pyplot as plt\n\n#treatment\ndonors_treat = df_positive[df_positive['treat'] == 1]['amount']\ndonors_ctrl = df_positive[df_positive['treat'] == 0]['amount']\n\n# 画图设置\nfig, ax = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# 控制组\nax[0].hist(donors_ctrl, bins=30, color='skyblue', edgecolor='black')\nax[0].axvline(donors_ctrl.mean(), color='red', linestyle='dashed', linewidth=2)\nax[0].set_title(\"Control Group: Donation Amounts\")\nax[0].set_xlabel(\"Amount\")\nax[0].set_ylabel(\"Number of Donors\")\n\n# 处理组\nax[1].hist(donors_treat, bins=30, color='lightgreen', edgecolor='black')\nax[1].axvline(donors_treat.mean(), color='red', linestyle='dashed', linewidth=2)\nax[1].set_title(\"Treatment Group: Donation Amounts\")\nax[1].set_xlabel(\"Amount\")\n\nplt.suptitle(\"Histograms of Donation Amounts (Among Donors)\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n```\n\nThe histograms show the distribution of donation amounts among donors only, with red dashed lines indicating group-specific average donations.\n\nThe treatment and control groups show similar right-skewed distributions, with most gifts clustered around $25–$75 and a few very large gifts (e.g., $250 or $400). The average donation was slightly higher in the control group, consistent with the regression results.\n\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic behaves under repeated sampling, I simulate the process of comparing two independent groups with known probabilities of donating:\n\nControl group: donation follows a Bernoulli distribution with probability p = 0.018\n\nTreatment group: donation follows a Bernoulli distribution with probability p = 0.022\n\nI simulate the sampling and testing process many times, and observe how the t-statistic behaves under different sample sizes.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n# Parameters\np_control = 0.018\np_treat = 0.022\nn_sims = 10000\nsample_sizes = [100, 500, 1000, 5000]\n\n# Function: simulate t-stats\ndef simulate_t_stats(n, sims=10000):\n    t_stats = []\n    for _ in range(sims):\n        control = np.random.binomial(1, p_control, size=n)\n        treat = np.random.binomial(1, p_treat, size=n)\n        t_stat, _ = stats.ttest_ind(treat, control)\n        t_stats.append(t_stat)\n    return t_stats\n\n# Run simulations\ntstat_results = {n: simulate_t_stats(n) for n in sample_sizes}\n```\n\n```{python}\n# Plot sampling distributions\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.ravel()\n\nfor i, n in enumerate(sample_sizes):\n    axes[i].hist(tstat_results[n], bins=40, density=True, color='skyblue', edgecolor='black')\n    axes[i].axvline(x=0, color='red', linestyle='--')\n    axes[i].set_title(f\"Sampling Distribution of t-stat (n = {n})\")\n    axes[i].set_xlabel(\"t-statistic\")\n    axes[i].set_ylabel(\"Density\")\n\nplt.suptitle(\"Sampling Distribution of t-statistics under Bernoulli Model\", fontsize=14)\nplt.tight_layout()\nplt.show()\n```\n\nInterpretation\nWhen sample size is small (e.g., n = 100), the t-statistic distribution is wide and noisy — it's hard to tell if there’s a real effect.\n\nAs sample size increases, the t-statistic distribution becomes narrower, and centered around the true difference (which is small, but positive).\n\nThis reflects the Law of Large Numbers: sample means converge to the population means.\n\nIt also illustrates the Central Limit Theorem: the difference in two sample means becomes approximately normally distributed as sample size grows.\n\nIn other words: with small samples, we might miss a real effect due to noise. But as sample size increases, our estimate of the effect and our test statistics become more stable and reliable.\n\n\n### Law of Large Numbers\n\nVisualization: Cumulative Average of Differences\n```{python}\n#| echo: false\n# Simulate draws\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(1, 0.018, size=100000)\ntreat_draws = np.random.binomial(1, 0.022, size=10000)\n\n# Only use first 10,000 for matching length\ncontrol_sample = control_draws[:10000]\n\n# Compute vector of differences (elementwise)\ndiffs = treat_draws - control_sample\n\n# Compute cumulative average of differences\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(10, 6))\nplt.plot(cum_avg, label='Cumulative Average of Differences')\nplt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers: Cumulative Average of Treatment - Control\")\nplt.xlabel(\"Number of Samples\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.show()\n```\n\nThe plot below shows the cumulative average of the differences in donation outcomes between simulated treatment and control groups:\n\n\nInitially, the average fluctuates wildly due to the high variance in small samples. For example, the first few differences swing far above and below the true mean.\n\nAs the number of samples increases, the cumulative average stabilizes and begins to hover around the true difference of 0.004, indicated by the red dashed line. This illustrates the Law of Large Numbers in practice: the more data we gather, the closer our estimate gets to the truth.\n\n### Central Limit Theorem\n\n```{python}\n# Parameters\np_c = 0.018\np_t = 0.022\nsample_sizes = [50, 200, 500, 1000]\nsim_count = 1000\n\n# Simulate average differences for each sample size\ndef simulate_avg_diffs(n, sims=1000):\n    diffs = []\n    for _ in range(sims):\n        control = np.random.binomial(1, p_c, size=n)\n        treatment = np.random.binomial(1, p_t, size=n)\n        diffs.append(np.mean(treatment) - np.mean(control))\n    return np.array(diffs)\n\n# Run simulations\nresults_clt = {n: simulate_avg_diffs(n) for n in sample_sizes}\n\n```\n\n```{python}\n#| echo: false\n# Plot histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.ravel()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = results_clt[n]\n    axes[i].hist(diffs, bins=40, color='lightblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='--', label='Zero (H₀)')\n    axes[i].axvline(0.004, color='green', linestyle='-', label='True Difference')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Average Difference (Treatment - Control)\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.suptitle(\"Sampling Distributions of Difference in Means\\n(Central Limit Theorem)\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n```\n\nInterpretation\nAt sample size = 50: The distribution is erratic, skewed, and shows wide dispersion. Zero is right in the center, meaning we likely wouldn't detect a small treatment effect.\n\nAt sample size = 200: The histogram becomes more symmetric and bell-shaped, and the true effect (green line) begins to emerge away from zero.\n\nAt sample size = 500: The distribution becomes much smoother and narrower. Zero starts moving toward the tail, suggesting a higher chance of rejecting the null.\n\nAt sample size = 1000: The distribution is tightly centered near the true difference of 0.004, and zero is well into the left tail—implying we would confidently detect the effect in most samples.\n\nThese plots visually confirm the Central Limit Theorem: as sample size increases, the sampling distribution of the sample mean difference:\n\nBecomes more normal in shape\n\nNarrows in spread (reduced variance)\n\nCenters around the true mean difference","srcMarkdownNoYaml":"\n\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nTo explore how different fundraising strategies influence donor behavior, Karlan and List leveraged a natural field experiment in collaboration with a real nonprofit organization. The 50,000 prior donors were randomly assigned to receive one of several versions of a direct mail solicitation. The control group received a standard appeal, while treatment groups received letters offering matching grants at different match ratios—1:1, 2:1, or 3:1. Each variation also manipulated the suggested donation amount and the maximum size of the matching gift. By analyzing the response rate and donation amounts across treatments, the authors were able to isolate the causal impact of these fundraising tactics on charitable giving.\n\nThis project seeks to replicate their results.\n\n\n## Data\n\n### Description\n\n```{python}\n#| echo: false\nimport pandas as pd\n\ndf = pd.read_stata(\"/Users/danielwang/Desktop/UCSD Spring/MGTA495 Marketing Analytics/Website/blog/project1/data/karlan_list_2007.dta\")\n\n```\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n```{python}\nimport statsmodels.api as sm\nfrom scipy import stats\n\n# Load data\ndf['treat'] = df['treatment'].fillna(0)\n\n# Balance test function\ndef balance_test(var):\n    df_sub = df[['treat', var]].dropna()\n    treat_group = df_sub[df_sub['treat'] == 1][var]\n    control_group = df_sub[df_sub['treat'] == 0][var]\n    \n    # T-test\n    t_stat, p_val = stats.ttest_ind(treat_group, control_group, equal_var=True)\n    mean_diff = treat_group.mean() - control_group.mean()\n\n    print(f\"\\n==== Balance Test for '{var}' ====\")\n    print(f\"T-test:\")\n    print(f\"  Mean (Treatment): {treat_group.mean():.3f}\")\n    print(f\"  Mean (Control):   {control_group.mean():.3f}\")\n    print(f\"  Difference:       {mean_diff:.3f}\")\n    print(f\"  t-statistic:      {t_stat:.3f}\")\n    print(f\"  p-value:          {p_val:.4f}\")\n\n    # OLS\n    X = sm.add_constant(df_sub['treat'])\n    model = sm.OLS(df_sub[var], X).fit()\n    print(\"\\nOLS Regression:\")\n    print(model.summary().tables[1])\n\n# Run tests\nfor var in ['mrm2', 'freq', 'hpa']:\n    balance_test(var)\n```\n\n## Experimental Results\nIn all cases, the null hypothesis of equal means cannot be rejected, and both t-tests and OLS regressions yield identical conclusions. The treatment assignment is statistically uncorrelated with these pre-treatment variables, providing strong evidence that the randomization mechanism worked as intended.\n\nWhy this matters: Table 1 in Karlan & List (2007) serves the same purpose—showing that groups were well-balanced at baseline. This is essential for internal validity: it ensures that any post-treatment differences in giving behavior can be credibly attributed to the treatment itself, not to pre-existing differences between donors.\n\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\n```{python}\n#| echo: false\nimport matplotlib.pyplot as plt\n\n# Create treatment indicator\ndf['treat'] = df['treatment'].fillna(0)\n\n# Group by treatment and compute mean of 'gave' (binary)\nprop_donated = df.groupby('treat')['gave'].mean()\n\n# Plot\nplt.bar(['Control', 'Treatment'], prop_donated, edgecolor='black')\nplt.title(\"Proportion of Donors by Treatment Group\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.ylim(0, 0.03)\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.show()\n```\n\nThe barplot below shows that 2.20% of individuals in the treatment group donated, compared to 1.79% in the control group.\n\n\n```{python}\n# T-test\ngave_treat = df[df['treat'] == 1]['gave']\ngave_control = df[df['treat'] == 0]['gave']\nt_stat, p_val = stats.ttest_ind(gave_treat, gave_control, equal_var=True)\n\nprint(\"T-test results:\")\nprint(f\"  Mean (Treatment): {gave_treat.mean():.4f}\")\nprint(f\"  Mean (Control):   {gave_control.mean():.4f}\")\nprint(f\"  Difference:       {gave_treat.mean() - gave_control.mean():.4f}\")\nprint(f\"  t-statistic:      {t_stat:.3f}\")\nprint(f\"  p-value:          {p_val:.4f}\")\n\n# OLS regression\nX = sm.add_constant(df['treat'])\nols_model = sm.OLS(df['gave'], X).fit()\nprint(\"\\nOLS Regression:\")\nprint(ols_model.summary().tables[1])\n```\n\nThe t-test and regression agree: the difference is statistically significant at the 1% level. Offering a matching grant increased the response rate by about 0.42 percentage points, which is approximately a 22% increase relative to the control group's donation rate.\n\n\n```{python}\n# Probit model\nprobit_model = sm.Probit(df['gave'], X).fit()\nprint(probit_model.summary())\n```\n\nThis replicates Table 3, Column 1 in the original paper, confirming that the treatment has a positive and statistically significant effect on the probability of donating.\n\nThese results show that simply informing potential donors that their gift would be matched made them more likely to give. Even though the absolute increase in donation rate is small, the relative effect is large and meaningful for fundraisers.\n\nThis supports the idea that donors are motivated not only by altruism, but also by how effective or impactful their contribution feels. The matching grant may act as a psychological signal that \"now is a good time to give\" or that their donation is more valuable than usual.\n\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n```{python}\n# treatment\ntreat_df = df[df['treat'] == 1].copy()\n\n# 1:1 vs 2:1\ngave_1 = treat_df[treat_df['ratio'] == 1]['gave']\ngave_2 = treat_df[treat_df['ratio'] == 2]['gave']\nt12, p12 = stats.ttest_ind(gave_1, gave_2)\n\n# 2:1 vs 3:1\ngave_3 = treat_df[treat_df['ratio'] == 3]['gave']\nt23, p23 = stats.ttest_ind(gave_2, gave_3)\n\nprint(f\"1:1 vs 2:1 match rate — p = {p12:.4f}\")\nprint(f\"2:1 vs 3:1 match rate — p = {p23:.4f}\")\nprint(f\"Means: 1:1 = {gave_1.mean():.4f}, 2:1 = {gave_2.mean():.4f}, 3:1 = {gave_3.mean():.4f}\")\n\n```\n\nThe results show no statistically significant differences in donation rates between the match levels. While there is a slight increase in the mean from 1:1 to 2:1 and 3:1, the p-values (0.33 and 0.96) confirm that these differences are not distinguishable from zero at conventional significance levels.\n\n\n```{python}\n# dummy\ntreat_df['ratio1'] = (treat_df['ratio'] == 1).astype(int)\ntreat_df['ratio2'] = (treat_df['ratio'] == 2).astype(int)\ntreat_df['ratio3'] = (treat_df['ratio'] == 3).astype(int)\n\n# ratio1\nX = sm.add_constant(treat_df[['ratio2', 'ratio3']])\ny = treat_df['gave']\nratio_model = sm.OLS(y, X).fit()\nprint(ratio_model.summary().tables[1])\n\n```\n\nThis regression supports the t-test findings. Neither the 2:1 nor 3:1 match ratio has a statistically significant effect relative to the 1:1 match. This aligns closely with Karlan & List’s statement that “larger match ratios… had no additional impact” (p. 8).\n\n\n```{python}\ndiff_21 = gave_2.mean() - gave_1.mean()\ndiff_32 = gave_3.mean() - gave_2.mean()\n\n# OLS \ncoef_diff_21 = ratio_model.params['ratio2']\ncoef_diff_32 = ratio_model.params['ratio3'] - ratio_model.params['ratio2']\n\nprint(f\"Data-based diff (2:1 - 1:1): {diff_21:.4f}\")\nprint(f\"Data-based diff (3:1 - 2:1): {diff_32:.4f}\")\nprint(f\"Model-based diff (2:1 - 1:1): {coef_diff_21:.4f}\")\nprint(f\"Model-based diff (3:1 - 2:1): {coef_diff_32:.4f}\")\n\n```\n\nBoth direct comparisons and model-based coefficient differences tell the same story: moving from 1:1 to 2:1 yields a small and statistically insignificant increase, and going from 2:1 to 3:1 yields essentially no change at all.\n\nThese results suggest that offering a match increases the chance of donation, but increasing the match ratio further does not enhance this effect. In other words, once the donor sees their gift will be matched, the degree of matching is not very motivating. This supports the notion that framing and salience—not just raw incentive size—drive much of charitable behavior.\n\nThis provides valuable insights for fundraisers: even modest matching offers (1:1) may be just as effective as more expensive ones (2:1 or 3:1) in driving participation.\n\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nT-test / Regression on Full Sample\n```{python}\n# reg\nX_full = sm.add_constant(df['treat'])\ny_amount = df['amount']\nmodel_full = sm.OLS(y_amount, X_full).fit()\n\nprint(\"OLS on all individuals:\")\nprint(model_full.summary().tables[1])\n```\nDependent variable: donation amount (all individuals)\n\n\nThis suggests that offering a matching grant increased the average donation amount by about $0.15. However, the result is only marginally significant (p ≈ 0.063). Since this regression includes non-donors (who gave $0), the result likely reflects the fact that more people gave at all in the treatment group.\n\n\nRegression Conditional on Donation\n```{python}\n# limit\ndf_positive = df[df['gave'] == 1]\n\nX_cond = sm.add_constant(df_positive['treat'])\ny_cond_amount = df_positive['amount']\nmodel_cond = sm.OLS(y_cond_amount, X_cond).fit()\n\nprint(\"\\nOLS on donors only (conditional on giving):\")\nprint(model_cond.summary().tables[1])\n```\n\nAmong those who actually donated, individuals in the treatment group gave slightly less, on average, than those in the control group—but this difference is small and statistically insignificant.\n\nThis suggests that the treatment did not affect how much people gave, once they decided to give. The treatment influenced the extensive margin (whether to donate), but not the intensive margin (how much to donate).\n\nCausal note: Since we are conditioning on a post-treatment outcome (gave), the regression on donors only does not have a causal interpretation. It is, however, still descriptively valuable.\n\n\n\nHistograms of Donation Amounts (Among Donors)\n```{python}\n#| echo: false\nimport matplotlib.pyplot as plt\n\n#treatment\ndonors_treat = df_positive[df_positive['treat'] == 1]['amount']\ndonors_ctrl = df_positive[df_positive['treat'] == 0]['amount']\n\n# 画图设置\nfig, ax = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# 控制组\nax[0].hist(donors_ctrl, bins=30, color='skyblue', edgecolor='black')\nax[0].axvline(donors_ctrl.mean(), color='red', linestyle='dashed', linewidth=2)\nax[0].set_title(\"Control Group: Donation Amounts\")\nax[0].set_xlabel(\"Amount\")\nax[0].set_ylabel(\"Number of Donors\")\n\n# 处理组\nax[1].hist(donors_treat, bins=30, color='lightgreen', edgecolor='black')\nax[1].axvline(donors_treat.mean(), color='red', linestyle='dashed', linewidth=2)\nax[1].set_title(\"Treatment Group: Donation Amounts\")\nax[1].set_xlabel(\"Amount\")\n\nplt.suptitle(\"Histograms of Donation Amounts (Among Donors)\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n```\n\nThe histograms show the distribution of donation amounts among donors only, with red dashed lines indicating group-specific average donations.\n\nThe treatment and control groups show similar right-skewed distributions, with most gifts clustered around $25–$75 and a few very large gifts (e.g., $250 or $400). The average donation was slightly higher in the control group, consistent with the regression results.\n\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic behaves under repeated sampling, I simulate the process of comparing two independent groups with known probabilities of donating:\n\nControl group: donation follows a Bernoulli distribution with probability p = 0.018\n\nTreatment group: donation follows a Bernoulli distribution with probability p = 0.022\n\nI simulate the sampling and testing process many times, and observe how the t-statistic behaves under different sample sizes.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n# Parameters\np_control = 0.018\np_treat = 0.022\nn_sims = 10000\nsample_sizes = [100, 500, 1000, 5000]\n\n# Function: simulate t-stats\ndef simulate_t_stats(n, sims=10000):\n    t_stats = []\n    for _ in range(sims):\n        control = np.random.binomial(1, p_control, size=n)\n        treat = np.random.binomial(1, p_treat, size=n)\n        t_stat, _ = stats.ttest_ind(treat, control)\n        t_stats.append(t_stat)\n    return t_stats\n\n# Run simulations\ntstat_results = {n: simulate_t_stats(n) for n in sample_sizes}\n```\n\n```{python}\n# Plot sampling distributions\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.ravel()\n\nfor i, n in enumerate(sample_sizes):\n    axes[i].hist(tstat_results[n], bins=40, density=True, color='skyblue', edgecolor='black')\n    axes[i].axvline(x=0, color='red', linestyle='--')\n    axes[i].set_title(f\"Sampling Distribution of t-stat (n = {n})\")\n    axes[i].set_xlabel(\"t-statistic\")\n    axes[i].set_ylabel(\"Density\")\n\nplt.suptitle(\"Sampling Distribution of t-statistics under Bernoulli Model\", fontsize=14)\nplt.tight_layout()\nplt.show()\n```\n\nInterpretation\nWhen sample size is small (e.g., n = 100), the t-statistic distribution is wide and noisy — it's hard to tell if there’s a real effect.\n\nAs sample size increases, the t-statistic distribution becomes narrower, and centered around the true difference (which is small, but positive).\n\nThis reflects the Law of Large Numbers: sample means converge to the population means.\n\nIt also illustrates the Central Limit Theorem: the difference in two sample means becomes approximately normally distributed as sample size grows.\n\nIn other words: with small samples, we might miss a real effect due to noise. But as sample size increases, our estimate of the effect and our test statistics become more stable and reliable.\n\n\n### Law of Large Numbers\n\nVisualization: Cumulative Average of Differences\n```{python}\n#| echo: false\n# Simulate draws\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(1, 0.018, size=100000)\ntreat_draws = np.random.binomial(1, 0.022, size=10000)\n\n# Only use first 10,000 for matching length\ncontrol_sample = control_draws[:10000]\n\n# Compute vector of differences (elementwise)\ndiffs = treat_draws - control_sample\n\n# Compute cumulative average of differences\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(10, 6))\nplt.plot(cum_avg, label='Cumulative Average of Differences')\nplt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers: Cumulative Average of Treatment - Control\")\nplt.xlabel(\"Number of Samples\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.show()\n```\n\nThe plot below shows the cumulative average of the differences in donation outcomes between simulated treatment and control groups:\n\n\nInitially, the average fluctuates wildly due to the high variance in small samples. For example, the first few differences swing far above and below the true mean.\n\nAs the number of samples increases, the cumulative average stabilizes and begins to hover around the true difference of 0.004, indicated by the red dashed line. This illustrates the Law of Large Numbers in practice: the more data we gather, the closer our estimate gets to the truth.\n\n### Central Limit Theorem\n\n```{python}\n# Parameters\np_c = 0.018\np_t = 0.022\nsample_sizes = [50, 200, 500, 1000]\nsim_count = 1000\n\n# Simulate average differences for each sample size\ndef simulate_avg_diffs(n, sims=1000):\n    diffs = []\n    for _ in range(sims):\n        control = np.random.binomial(1, p_c, size=n)\n        treatment = np.random.binomial(1, p_t, size=n)\n        diffs.append(np.mean(treatment) - np.mean(control))\n    return np.array(diffs)\n\n# Run simulations\nresults_clt = {n: simulate_avg_diffs(n) for n in sample_sizes}\n\n```\n\n```{python}\n#| echo: false\n# Plot histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.ravel()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = results_clt[n]\n    axes[i].hist(diffs, bins=40, color='lightblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='--', label='Zero (H₀)')\n    axes[i].axvline(0.004, color='green', linestyle='-', label='True Difference')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Average Difference (Treatment - Control)\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.suptitle(\"Sampling Distributions of Difference in Means\\n(Central Limit Theorem)\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n```\n\nInterpretation\nAt sample size = 50: The distribution is erratic, skewed, and shows wide dispersion. Zero is right in the center, meaning we likely wouldn't detect a small treatment effect.\n\nAt sample size = 200: The histogram becomes more symmetric and bell-shaped, and the true effect (green line) begins to emerge away from zero.\n\nAt sample size = 500: The distribution becomes much smoother and narrower. Zero starts moving toward the tail, suggesting a higher chance of rejecting the null.\n\nAt sample size = 1000: The distribution is tightly centered near the true difference of 0.004, and zero is well into the left tail—implying we would confidently detect the effect in most samples.\n\nThese plots visually confirm the Central Limit Theorem: as sample size increases, the sampling distribution of the sample mean difference:\n\nBecomes more normal in shape\n\nNarrows in spread (reduced variance)\n\nCenters around the true mean difference"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.23","theme":["cosmo","brand"],"title":"A Replication of Karlan and List (2007)","author":"Dingran Wang","date":"04/21/2025","callout-appearance":"minimal"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}